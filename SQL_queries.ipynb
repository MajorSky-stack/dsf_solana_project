{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb645716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14df5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to Snowflake Account\n",
    "conn = snowflake.connector.connect(\n",
    "    user=\"USERNAME\",\n",
    "    password=\"Your_Sn0wflak3_Password\",\n",
    "    account=\"IMTFQZV-DPC01467\",\n",
    "    warehouse=\"COMPUTE_WH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49814bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x2464c7b3b60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define block range parameters within SQL query\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SET min_block_id = 379995000\")\n",
    "cur.execute(\"SET max_block_id = 380000000\")\n",
    "cur.execute(\"SET max_limit   =  10000000000\")\n",
    "cur.execute(\"SET min_season_block = 379995000\")\n",
    "cur.execute(\"SET max_season_block = 380000000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d90d3",
   "metadata": {},
   "source": [
    "### Note:\n",
    "The above block range is only for fast exectution. For our final results, we used the block ranges below, which we exported as csv and load into pandas later in the code. The goal was to enable this notebook to be run by anyone without incurring high compute costs or long wait times, yet still provide the full data for analysis.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "What we actually used for the final query:<br>\n",
    "cur.execute(\"SET min_block_id = 379899000\") <br>\n",
    "cur.execute(\"SET max_block_id = 380000000\")<br>\n",
    "cur.execute(\"SET max_limit   =  100000000000\")<br>\n",
    "cur.execute(\"SET min_season_block = 300000000\")<br>\n",
    "cur.execute(\"SET max_season_block = 380000000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69307c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = \"\"\"\n",
    "\n",
    "--Define all the intermediary dataframes\n",
    "WITH\n",
    "\n",
    "/*\n",
    "Define t1 as the \"main\" dataset we will JOIN on later.\n",
    "This is the dataset containing all the fee columns.\n",
    "We have to flatten instructions twice in order to access the account value\n",
    "This account value corresponds to the ORCA SOL-USDC pool\n",
    "Moreover, we rank over priority_fee to get the ordering within the same block, both in absolute and quantile values.\n",
    "We take this data from the SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TRANSACTIONS database, containing all transaction details (importantly fees)\n",
    "*/\n",
    "\n",
    "--Define t1 as the main one, with priority fees\n",
    "t1 AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            BLOCK_ID AS block,\n",
    "            FEE AS fee,\n",
    "            TX_ID AS tx_id,\n",
    "            FEE - 5000 AS priority_fee,\n",
    "\n",
    "            RANK() OVER (\n",
    "                PARTITION BY BLOCK_ID\n",
    "                ORDER BY (FEE - 5000) DESC\n",
    "            ) AS fee_rank_desc,\n",
    "\n",
    "            (RANK() OVER (\n",
    "                PARTITION BY BLOCK_ID\n",
    "                ORDER BY (FEE - 5000) DESC\n",
    "            ) * 1.0)\n",
    "            /\n",
    "            (COUNT(*) OVER (PARTITION BY BLOCK_ID)) AS quantile_position\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TRANSACTIONS AS tr,\n",
    "             LATERAL FLATTEN(input => tr.instructions) AS inst,\n",
    "             LATERAL FLATTEN(input => inst.value:accounts) AS acct\n",
    "\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND SUCCEEDED = TRUE\n",
    "            AND acct.value::string = 'FksffEqnBRixYGR791Qw2MgdU7zNCpHVFYBL4Fa4qVuH'\n",
    "\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "/*\n",
    "We now create multiple datasets, each for the price of a specific pool\n",
    "Conceptually, we take the dataset containing the account changes, select the USDC token (''EPjF...),\n",
    "compute the absolute difference between before and after the transaction. We do the same for the SOL token ('So111...')\n",
    "Then, We divide the absolute change in USDC by the absolute change in SOL and take it as the price.\n",
    "We do this because it is not possible to get a reliable data for price per block per account. Moreover, this seems to be\n",
    "surprisingly accurate, as most accounts have very similar prices and it matches the real, historic price we can see on M1 candles\n",
    "on charting softwares.\n",
    "Finally, we only take rows where the owner (account) is the pool that interests us.\n",
    "\n",
    "\n",
    "We had to take this data from the SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES database, containg information on token balances (which\n",
    "we use to reconstruct price)\n",
    "*/\n",
    "\n",
    "\n",
    "t2_Fksff AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "            MIN(TX_INDEX) AS TX_INDEX,\n",
    "\n",
    "            ABS(\n",
    "                SUM(\n",
    "                    CASE\n",
    "                        WHEN MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                        THEN BALANCE - PRE_BALANCE\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                )\n",
    "            )\n",
    "            /\n",
    "            NULLIF(\n",
    "                ABS(\n",
    "                    SUM(\n",
    "                        CASE\n",
    "                            WHEN MINT = 'So11111111111111111111111111111111111111112'\n",
    "                            THEN BALANCE - PRE_BALANCE\n",
    "                            ELSE 0\n",
    "                        END\n",
    "                    )\n",
    "                ),\n",
    "                0\n",
    "            ) AS Fksff_price\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND OWNER = 'FksffEqnBRixYGR791Qw2MgdU7zNCpHVFYBL4Fa4qVuH'\n",
    "\n",
    "        GROUP BY TX_ID\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "t2_Czfq3 AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "            MIN(TX_INDEX) AS TX_INDEX,\n",
    "\n",
    "            ABS(\n",
    "                SUM(\n",
    "                    CASE\n",
    "                        WHEN MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                        THEN BALANCE - PRE_BALANCE\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                )\n",
    "            )\n",
    "            /\n",
    "            NULLIF(\n",
    "                ABS(\n",
    "                    SUM(\n",
    "                        CASE\n",
    "                            WHEN MINT = 'So11111111111111111111111111111111111111112'\n",
    "                            THEN BALANCE - PRE_BALANCE\n",
    "                            ELSE 0\n",
    "                        END\n",
    "                    )\n",
    "                ),\n",
    "                0\n",
    "            ) AS Czfq3_price\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND OWNER = 'Czfq3xZZDmsdGdUyrNLtRhGc47cXcZtLG4crryfu44zE'\n",
    "\n",
    "        GROUP BY TX_ID\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "t2_DB3sU AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "            MIN(TX_INDEX) AS TX_INDEX,\n",
    "\n",
    "            ABS(\n",
    "                SUM(\n",
    "                    CASE\n",
    "                        WHEN MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                        THEN BALANCE - PRE_BALANCE\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                )\n",
    "            )\n",
    "            /\n",
    "            NULLIF(\n",
    "                ABS(\n",
    "                    SUM(\n",
    "                        CASE\n",
    "                            WHEN MINT = 'So11111111111111111111111111111111111111112'\n",
    "                            THEN BALANCE - PRE_BALANCE\n",
    "                            ELSE 0\n",
    "                        END\n",
    "                    )\n",
    "                ),\n",
    "                0\n",
    "            ) AS DB3sU_price\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND OWNER = 'DB3sUCP2H4icbeKmK6yb6nUxU5ogbcRHtGuq7W2RoRwW'\n",
    "\n",
    "        GROUP BY TX_ID\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "t2_n9VhC AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "            MIN(TX_INDEX) AS TX_INDEX,\n",
    "\n",
    "            ABS(\n",
    "                SUM(\n",
    "                    CASE\n",
    "                        WHEN MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                        THEN BALANCE - PRE_BALANCE\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                )\n",
    "            )\n",
    "            /\n",
    "            NULLIF(\n",
    "                ABS(\n",
    "                    SUM(\n",
    "                        CASE\n",
    "                            WHEN MINT = 'So11111111111111111111111111111111111111112'\n",
    "                            THEN BALANCE - PRE_BALANCE\n",
    "                            ELSE 0\n",
    "                        END\n",
    "                    )\n",
    "                ),\n",
    "                0\n",
    "            ) AS n9VhC_price\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND OWNER = '6n9VhCwQ7EwK6NqFDjnHPzEk6wZdRBTfh43RFgHQWHuQ'\n",
    "\n",
    "        GROUP BY TX_ID\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "t2_AvGeF AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "            MIN(TX_INDEX) AS TX_INDEX,\n",
    "\n",
    "            ABS(\n",
    "                SUM(\n",
    "                    CASE\n",
    "                        WHEN MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                        THEN BALANCE - PRE_BALANCE\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                )\n",
    "            )\n",
    "            /\n",
    "            NULLIF(\n",
    "                ABS(\n",
    "                    SUM(\n",
    "                        CASE\n",
    "                            WHEN MINT = 'So11111111111111111111111111111111111111112'\n",
    "                            THEN BALANCE - PRE_BALANCE\n",
    "                            ELSE 0\n",
    "                        END\n",
    "                    )\n",
    "                ),\n",
    "                0\n",
    "            ) AS AvGeF_price\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND OWNER = 'AvGeFw71N5sNfV97mZ1uNrHg4yfufRicCJUrS9j2ehTX'\n",
    "\n",
    "        GROUP BY TX_ID\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "t2_ucNos AS (\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "            MIN(TX_INDEX) AS TX_INDEX,\n",
    "\n",
    "            ABS(\n",
    "                SUM(\n",
    "                    CASE\n",
    "                        WHEN MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                        THEN BALANCE - PRE_BALANCE\n",
    "                        ELSE 0\n",
    "                    END\n",
    "                )\n",
    "            )\n",
    "            /\n",
    "            NULLIF(\n",
    "                ABS(\n",
    "                    SUM(\n",
    "                        CASE\n",
    "                            WHEN MINT = 'So11111111111111111111111111111111111111112'\n",
    "                            THEN BALANCE - PRE_BALANCE\n",
    "                            ELSE 0\n",
    "                        END\n",
    "                    )\n",
    "                ),\n",
    "                0\n",
    "            ) AS ucNos_price\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "        WHERE\n",
    "            BLOCK_ID > $min_block_id\n",
    "            AND BLOCK_ID < $max_block_id\n",
    "            AND OWNER = '3ucNos4NbumPLZNWztqGHNFFgkHeRMBQAVemeeomsUxv'\n",
    "\n",
    "        GROUP BY TX_ID\n",
    "        ORDER BY BLOCK_ID, TX_ID\n",
    "        LIMIT $max_limit\n",
    "    )\n",
    "),\n",
    "\n",
    "/*\n",
    "In this dataset, we compute the total volume accross multiple accounts. We apply the same trick as before,\n",
    "summing the absolute values of the difference between pre and post balances (only USDC this time).\n",
    "We group by block id, since we want volume for the whole block\n",
    "*/\n",
    "\n",
    "\n",
    "t3 AS (\n",
    "    SELECT\n",
    "        MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "        AVG(\n",
    "            CASE\n",
    "                WHEN OWNER = 'Czfq3xZZDmsdGdUyrNLtRhGc47cXcZtLG4crryfu44zE'\n",
    "                     AND MINT = 'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v'\n",
    "                THEN BALANCE\n",
    "            END\n",
    "        ) AS avg_balance,\n",
    "\n",
    "        SUM(\n",
    "            CASE\n",
    "                WHEN MINT IN (\n",
    "                    'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v',\n",
    "                    'Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB'\n",
    "                )\n",
    "                THEN ABS(BALANCE - PRE_BALANCE)\n",
    "                ELSE 0\n",
    "            END\n",
    "        ) AS volume\n",
    "\n",
    "    FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TOKEN_BALANCES\n",
    "    WHERE\n",
    "        BLOCK_ID > $min_block_id\n",
    "        AND BLOCK_ID < $max_block_id\n",
    "        AND OWNER IN (\n",
    "            'FksffEqnBRixYGR791Qw2MgdU7zNCpHVFYBL4Fa4qVuH',\n",
    "            'Czfq3xZZDmsdGdUyrNLtRhGc47cXcZtLG4crryfu44zE',\n",
    "            'DB3sUCP2H4icbeKmK6yb6nUxU5ogbcRHtGuq7W2RoRwW',\n",
    "            '6n9VhCwQ7EwK6NqFDjnHPzEk6wZdRBTfh43RFgHQWHuQ',\n",
    "            'AvGeFw71N5sNfV97mZ1uNrHg4yfufRicCJUrS9j2ehTX',\n",
    "            '3ucNos4NbumPLZNWztqGHNFFgkHeRMBQAVemeeomsUxv',\n",
    "            '58oQChx4yWmvKdwLLZzBi4ChoCc2fqCUWBkwMihLYQo2',\n",
    "            '7VuKeevbvbQQcxz6N4SNLmuq6PYy4AcGQRDssoqo4t65',\n",
    "            'FLckHLGMJy5gEoXWwcE68Nprde1D4araK4TGLw4pQq2n',\n",
    "            'BGm1tav58oGcsQJehL9WXBFXF7D27vZsKefj4xJKD5Y',\n",
    "            '8Pm2kZpnxD3hoMmt4bjStX2Pw2Z9abpbHzZxMPqxPmie',\n",
    "            'FwewVm8u6tFPGewAyHmWAqad9hmF7mvqxK4mJ7iNqqGC',\n",
    "            '3nMFwZXwY1s1M5s8vYAHqd4wGs4iSxXE4LRoUMMYqEgF',\n",
    "            'EiEAydLqSKFqRPpuwYoVxEJ6h9UZh9tsTaHgs4f8b8Z5',\n",
    "            '7XawhbbxtsRcQA8KTkHT9f9nc6d69UwqCDh6U5EEbEmX'\n",
    "        )\n",
    "\n",
    "    GROUP BY BLOCK_ID\n",
    "    ORDER BY BLOCK_ID\n",
    "    LIMIT $max_limit\n",
    "),\n",
    "\n",
    "/*\n",
    "We then compute average volume over the last 999 blocks (around 8 minutes), giving a slightly more macro perspective.\n",
    "We decided to create a new dataset instead of implementing it in t3 directly because we were concerned that the 999 row limit\n",
    "would only select the last 999 rows, and not the last 999 blocks. (We are slightly unsure if this concern is accurate or not,\n",
    "but doing it like this seemed more conservative, although less concise)\n",
    "*/\n",
    "\n",
    "\n",
    "t3_1 AS (\n",
    "    SELECT\n",
    "        BLOCK_ID,\n",
    "        AVG(volume) OVER (\n",
    "            ORDER BY BLOCK_ID\n",
    "            ROWS BETWEEN 999 PRECEDING AND CURRENT ROW\n",
    "        ) AS avg_volume_last_999_blocks\n",
    "    FROM t3\n",
    "),\n",
    "\n",
    "/*\n",
    "This dataset sums and averages priority fees paid in each block. We will use this later to compute\n",
    "the average and summed fees in the last n blocks (creating new columns).\n",
    "Naturally, we group by block.\n",
    "*/\n",
    "\n",
    "t4 AS (\n",
    "    SELECT\n",
    "        block,\n",
    "        SUM(priority_fee) AS block_fee_sum,\n",
    "        AVG(priority_fee) AS block_fee_avg\n",
    "    FROM t1\n",
    "    GROUP BY block\n",
    "),\n",
    "\n",
    "/*\n",
    "Here, we sort of do an intermediary step, joining all the datasets and using this more concentrated dataset for the final database.\n",
    "This is because we wanted to compute price changes, but this first necessitates some cleaning and doing it in a single SELECT\n",
    "would have been less understandable.\n",
    "\n",
    "First, we take all prices from the t2_xxxxx databases and replace with the last recorded price in case the current price is inexistant (possible \n",
    "for illiquid pools).\n",
    "Importantly, this LAST_VALUE function enables us to select only the last transaction of the previous block (found by looking at the highest TX_INDEX).\n",
    "This ensures that the price we consider is the very last price paid in the previous block.\n",
    "\n",
    "Then, we add all the columns for the avg and summed priority fees in the previous 10 blocks, defining the delay in the JOIN directly.\n",
    "Correspondingly, we JOIN most databases on BLOCK_ID + 1, ensuring that the data for the current block come from the last block (which is the last information visible live).\n",
    "This means for example that the price is the price of the last block, not the current block, effectively avoiding data leakage or useless predictions.\n",
    "\n",
    "We then do a qualify to keep only one row per tx_id (multiple where created during the prices databases, because one transaction id\n",
    "is actually split into multiple for each action of the transaction (buy SOL and sell USDC for example)).\n",
    "*/\n",
    "\n",
    "pre_final AS (\n",
    "    SELECT\n",
    "        t1.block,\n",
    "        t1.tx_id,\n",
    "        t1.priority_fee,\n",
    "        t1.fee_rank_desc,\n",
    "        t1.quantile_position,\n",
    "        t3.volume,\n",
    "\n",
    "        LAST_VALUE(t3.avg_balance IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t3.block_id\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS avg_balance,\n",
    "\n",
    "        LAST_VALUE(t2_Fksff.Fksff_price IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t2_Fksff.TX_INDEX\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS Fksff_price,\n",
    "\n",
    "        LAST_VALUE(t2_Czfq3.Czfq3_price IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t2_Czfq3.TX_INDEX\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS Czfq3_price,\n",
    "\n",
    "        LAST_VALUE(t2_DB3sU.DB3sU_price IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t2_DB3sU.TX_INDEX\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS DB3sU_price,\n",
    "\n",
    "        LAST_VALUE(t2_n9VhC.n9VhC_price IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t2_n9VhC.TX_INDEX\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS n9VhC_price,\n",
    "\n",
    "        LAST_VALUE(t2_AvGeF.AvGeF_price IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t2_AvGeF.TX_INDEX\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS AvGeF_price,\n",
    "\n",
    "        LAST_VALUE(t2_ucNos.ucNos_price IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block, t2_ucNos.TX_INDEX\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS ucNos_price,\n",
    "\n",
    "        LAST_VALUE(t3_1.avg_volume_last_999_blocks IGNORE NULLS) OVER (\n",
    "            ORDER BY t1.block\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) AS avg_volume_last_999,\n",
    "\n",
    "        -- exactly 1 block before\n",
    "        b1.block_fee_sum AS sum_block_minus_1,\n",
    "        b1.block_fee_avg AS avg_block_minus_1,\n",
    "\n",
    "        -- exactly 2 blocks before\n",
    "        b2.block_fee_sum AS sum_block_minus_2,\n",
    "        b2.block_fee_avg AS avg_block_minus_2,\n",
    "\n",
    "        -- exactly 3 blocks before\n",
    "        b3.block_fee_sum AS sum_block_minus_3,\n",
    "        b3.block_fee_avg AS avg_block_minus_3,\n",
    "\n",
    "        -- exactly 4 blocks before\n",
    "        b4.block_fee_sum AS sum_block_minus_4,\n",
    "        b4.block_fee_avg AS avg_block_minus_4,\n",
    "\n",
    "        -- exactly 5 blocks before\n",
    "        b5.block_fee_sum AS sum_block_minus_5,\n",
    "        b5.block_fee_avg AS avg_block_minus_5,\n",
    "\n",
    "        -- exactly 6 blocks before\n",
    "        b6.block_fee_sum AS sum_block_minus_6,\n",
    "        b6.block_fee_avg AS avg_block_minus_6,\n",
    "\n",
    "        -- exactly 7 blocks before\n",
    "        b7.block_fee_sum AS sum_block_minus_7,\n",
    "        b7.block_fee_avg AS avg_block_minus_7,\n",
    "\n",
    "        -- exactly 8 blocks before\n",
    "        b8.block_fee_sum AS sum_block_minus_8,\n",
    "        b8.block_fee_avg AS avg_block_minus_8,\n",
    "\n",
    "        -- exactly 9 blocks before\n",
    "        b9.block_fee_sum AS sum_block_minus_9,\n",
    "        b9.block_fee_avg AS avg_block_minus_9,\n",
    "\n",
    "        -- exactly 10 blocks before\n",
    "        b10.block_fee_sum AS sum_block_minus_10,\n",
    "        b10.block_fee_avg AS avg_block_minus_10,\n",
    "\n",
    "        t3_1.avg_volume_last_999_blocks\n",
    "\n",
    "    FROM t1\n",
    "\n",
    "    LEFT JOIN t2_Fksff ON t1.block = t2_Fksff.BLOCK_ID + 1\n",
    "    LEFT JOIN t2_Czfq3 ON t1.block = t2_Czfq3.BLOCK_ID + 1\n",
    "    LEFT JOIN t2_DB3sU ON t1.block = t2_DB3sU.BLOCK_ID + 1\n",
    "    LEFT JOIN t2_n9VhC ON t1.block = t2_n9VhC.BLOCK_ID + 1\n",
    "    LEFT JOIN t2_AvGeF ON t1.block = t2_AvGeF.BLOCK_ID + 1\n",
    "    LEFT JOIN t2_ucNos ON t1.block = t2_ucNos.BLOCK_ID + 1\n",
    "\n",
    "    LEFT JOIN t3   ON t1.block = t3.BLOCK_ID + 1\n",
    "    LEFT JOIN t3_1 ON t1.block = t3_1.BLOCK_ID + 1\n",
    "\n",
    "    LEFT JOIN t4 b1  ON b1.block  = t1.block - 1\n",
    "    LEFT JOIN t4 b2  ON b2.block  = t1.block - 2\n",
    "    LEFT JOIN t4 b3  ON b3.block  = t1.block - 3\n",
    "    LEFT JOIN t4 b4  ON b4.block  = t1.block - 4\n",
    "    LEFT JOIN t4 b5  ON b5.block  = t1.block - 5\n",
    "    LEFT JOIN t4 b6  ON b6.block  = t1.block - 6\n",
    "    LEFT JOIN t4 b7  ON b7.block  = t1.block - 7\n",
    "    LEFT JOIN t4 b8  ON b8.block  = t1.block - 8\n",
    "    LEFT JOIN t4 b9  ON b9.block  = t1.block - 9\n",
    "    LEFT JOIN t4 b10 ON b10.block = t1.block - 10\n",
    "\n",
    "    QUALIFY ROW_NUMBER() OVER (\n",
    "        PARTITION BY t1.tx_id\n",
    "        ORDER BY t2_Fksff.tx_index DESC\n",
    "    ) = 1\n",
    "\n",
    "    ORDER BY\n",
    "        t1.block,\n",
    "        t1.tx_id\n",
    "),\n",
    "\n",
    "/*\n",
    "We now create 3 small intermediary dataframes for missing features needed.\n",
    "First, we create a time dataframe that aggregates time by 30m blocks, which will be needed for a later merge in pandas with the seasonality dataframe\n",
    "*/\n",
    "\n",
    "time AS (\n",
    "    SELECT\n",
    "        MIN(BLOCK_TIMESTAMP),\n",
    "        BLOCK_ID,\n",
    "        MIN(TIME_SLICE(BLOCK_TIMESTAMP, 30, 'MINUTE')) AS block_ts_30m\n",
    "    FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TRANSACTIONS\n",
    "    WHERE BLOCK_ID > $min_block_id\n",
    "      AND BLOCK_ID < $max_block_id\n",
    "    GROUP BY BLOCK_ID\n",
    "    ORDER BY BLOCK_ID\n",
    "    LIMIT $max_limit\n",
    "),\n",
    "\n",
    "/*\n",
    "We create last_block, which basically counts the number of transactions in the current block (which will be the last block in the merge)\n",
    "*/\n",
    "\n",
    "last_block AS (\n",
    "    SELECT\n",
    "        COUNT(*) AS tx_count_in_block,\n",
    "        MIN(block) AS block\n",
    "    FROM t1\n",
    "    WHERE block > $min_block_id\n",
    "      AND block < $max_block_id\n",
    "    GROUP BY block\n",
    "    ORDER BY block\n",
    "),\n",
    "\n",
    "/*\n",
    "We create last_total, which returns features for all transactions in a given block, not just the ones on our specific pool.\n",
    "We thus return total transactions, block id (for the merge), total fees and units consumed\n",
    "*/\n",
    "\n",
    "last_total AS (\n",
    "    SELECT\n",
    "        COUNT(*) AS total_transactions,\n",
    "        MIN(BLOCK_ID) AS BLOCK_ID,\n",
    "        SUM(FEE) AS total_fee,\n",
    "        SUM(UNITS_CONSUMED) AS units_consumed\n",
    "    FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TRANSACTIONS AS tr\n",
    "    WHERE BLOCK_ID > $min_block_id\n",
    "      AND BLOCK_ID < $max_block_id\n",
    "    GROUP BY BLOCK_ID\n",
    "    ORDER BY BLOCK_ID\n",
    ")\n",
    "\n",
    "/*\n",
    "This is the final SELECT (the one we actually access in Python).\n",
    "We only take values from the pre_final, time, last_block and last_total databases (with joins).\n",
    "The only mathematical operation we do here is define the prices as their relative value compared to our target pool (in %).\n",
    "*/\n",
    "\n",
    "\n",
    "SELECT\n",
    "    pre_final.block,\n",
    "    priority_fee,\n",
    "    fee_rank_desc,\n",
    "    quantile_position,\n",
    "    volume,\n",
    "    avg_balance,\n",
    "    Fksff_price,\n",
    "    time.BLOCK_TS_30M,\n",
    "    tx_count_in_block,\n",
    "    last_total.total_transactions,\n",
    "    last_total.total_fee,\n",
    "    last_total.units_consumed,\n",
    "\n",
    "    Czfq3_price,\n",
    "\n",
    "    ((Czfq3_price - Fksff_price) / NULLIF(Fksff_price, 0)) * 100\n",
    "        AS pct_diff_czfq3_fksff,\n",
    "\n",
    "    ((Czfq3_price - DB3sU_price) / NULLIF(DB3sU_price, 0)) * 100\n",
    "        AS pct_diff_czfq3_db3su,\n",
    "\n",
    "    ((Czfq3_price - n9VhC_price) / NULLIF(n9VhC_price, 0)) * 100\n",
    "        AS pct_diff_czfq3_n9vhc,\n",
    "\n",
    "    ((Czfq3_price - AvGeF_price) / NULLIF(AvGeF_price, 0)) * 100\n",
    "        AS pct_diff_czfq3_avgef,\n",
    "\n",
    "    ((Czfq3_price - ucNos_price) / NULLIF(ucNos_price, 0)) * 100\n",
    "        AS pct_diff_czfq3_ucnos,\n",
    "\n",
    "    (\n",
    "        (Czfq3_price - (\n",
    "            (Fksff_price +\n",
    "             DB3sU_price +\n",
    "             n9VhC_price +\n",
    "             AvGeF_price +\n",
    "             ucNos_price) / 5\n",
    "        ))\n",
    "        /\n",
    "        NULLIF(\n",
    "            (Fksff_price +\n",
    "             DB3sU_price +\n",
    "             n9VhC_price +\n",
    "             AvGeF_price +\n",
    "             ucNos_price) / 5,\n",
    "            0\n",
    "        )\n",
    "    ) * 100 AS pct_diff_czfq3_vs_avg,\n",
    "\n",
    "    -- SUM history\n",
    "    sum_block_minus_1,\n",
    "    sum_block_minus_2,\n",
    "    sum_block_minus_3,\n",
    "    sum_block_minus_4,\n",
    "    sum_block_minus_5,\n",
    "    sum_block_minus_6,\n",
    "    sum_block_minus_7,\n",
    "    sum_block_minus_8,\n",
    "    sum_block_minus_9,\n",
    "    sum_block_minus_10,\n",
    "\n",
    "    -- AVG history\n",
    "    avg_block_minus_1,\n",
    "    avg_block_minus_2,\n",
    "    avg_block_minus_3,\n",
    "    avg_block_minus_4,\n",
    "    avg_block_minus_5,\n",
    "    avg_block_minus_6,\n",
    "    avg_block_minus_7,\n",
    "    avg_block_minus_8,\n",
    "    avg_block_minus_9,\n",
    "    avg_block_minus_10,\n",
    "\n",
    "    avg_volume_last_999\n",
    "\n",
    "FROM pre_final\n",
    "LEFT JOIN time\n",
    "    ON pre_final.block = time.BLOCK_ID\n",
    "LEFT JOIN last_block\n",
    "    ON pre_final.block = last_block.block + 1\n",
    "LEFT JOIN last_total\n",
    "    ON pre_final.block = last_total.BLOCK_ID + 1\n",
    "\n",
    "--Skip the first 50 transactions to handle potential missing values (in reality we would have used 1000, but since the test query is smaller, we only put 50 here)\n",
    "WHERE pre_final.block > $min_block_id + 50\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aaf4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality = \"\"\"\n",
    "\n",
    "/*\n",
    "We create temporary dataframe (just as before) with only priority fees, block and block_timestamp.\n",
    "We group it by blocks (summing the priority fees per block)\n",
    "We define the 30m time slices to to a grouping just after\n",
    "*/\n",
    "\n",
    "WITH t1 AS (\n",
    "SELECT\n",
    "            MIN(BLOCK_ID) AS block,\n",
    "            MIN(BLOCK_TIMESTAMP),\n",
    "            MIN(TIME_SLICE(BLOCK_TIMESTAMP, 30, 'MINUTE')) AS block_ts_30m,\n",
    "\n",
    "            SUM(FEE - 5000) as priority_fee,\n",
    "\n",
    "        FROM SOLANA_ONCHAIN_CORE_DATA.CORE.FACT_TRANSACTIONS AS tr,\n",
    "\n",
    "             LATERAL FLATTEN(input => tr.instructions) AS inst,\n",
    "             LATERAL FLATTEN(input => inst.value:accounts) AS acct\n",
    "             \n",
    "        WHERE\n",
    "            BLOCK_ID > $min_season_block\n",
    "            AND BLOCK_ID < $max_season_block\n",
    "            AND SUCCEEDED = TRUE\n",
    "            AND acct.value::string = 'Czfq3xZZDmsdGdUyrNLtRhGc47cXcZtLG4crryfu44zE'\n",
    "\n",
    "\n",
    "        GROUP BY BLOCK_ID\n",
    "        ORDER BY BLOCK_ID\n",
    "\n",
    "    )\n",
    "\n",
    "/*\n",
    "Here, we select the dataframe we just created and group by 30m block, again summing the fees.\n",
    "There probably would have been a way to do it in just one SELECT, but this seemed simpler.\n",
    "*/\n",
    "\n",
    "SELECT \n",
    "        MIN(block_ts_30m) as block_ts_30m,\n",
    "        SUM(priority_fee) as priority_fee\n",
    "\n",
    "FROM t1\n",
    "\n",
    "GROUP BY block_ts_30m\n",
    "ORDER BY block_ts_30m\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96ea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\killian\\AppData\\Local\\Temp\\ipykernel_36540\\3849388530.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  main_df = pd.read_sql(main, conn)\n",
      "C:\\Users\\killian\\AppData\\Local\\Temp\\ipykernel_36540\\3849388530.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  seasonality_df = pd.read_sql(seasonality, conn)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Loading both databases in Pandas using the Snowflake connector\n",
    "# =============================================================================\n",
    "\n",
    "main_df = pd.read_sql(main, conn)\n",
    "seasonality_df = pd.read_sql(seasonality, conn)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Export both databases to csv\n",
    "# =============================================================================\n",
    "\n",
    "main_df.to_csv(\"data_5k.csv\")\n",
    "seasonality_df.to_csv(\"seasonality_uncomplete.csv\")\n",
    "#Note: It's completely normal that there are only two rows in seasonality_uncomplete, it's because\n",
    "#the block range used for this query is very small"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
